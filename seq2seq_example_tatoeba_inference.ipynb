{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import json\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from seq2seq.rnn_seq2seq import create_seq2seq_model\n",
    "from seq2seq.input.generator_io import generator_input_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from train_parallel_corpora import load_vocab, file_data_generator_py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "unk_id = 2\n",
    "vocab_ids_bias = unk_id + 1\n",
    "vocab2id, id2vocab = load_vocab(\"./data/tatoeba_en_ru/vocab.txt\", ids_bias=vocab_ids_bias)\n",
    "encode = lambda line: list(map(lambda x: vocab2id.get(x, unk_id), line.split(\" \")))\n",
    "decode = lambda line: \" \".join(list(map(lambda x: id2vocab.get(x, \" \"), line))).strip()\n",
    "vocab_size = len(vocab2id) + vocab_ids_bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "том сказал что больше этого делать не будет\r\n",
      "tom said he wouldnt do that again\r\n",
      "у тома добро@@ е сердце\r\n",
      "tom has a good heart\r\n",
      "мне не@@ где остановиться\r\n",
      "i have nowhere to stay\r\n",
      "пожалуйста объяс@@ ни мне правила футбо@@ ла\r\n",
      "please explain the rules of soccer to me\r\n",
      "он ушёл\r\n",
      "he went away\r\n"
     ]
    }
   ],
   "source": [
    "! head -10 ./data/tatoeba_en_ru/test.txt | awk -F '\\t' '{print $2}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "val_input_fn = generator_input_fn(\n",
    "    x=file_data_generator_py(\"./data/tatoeba_en_ru/test.txt\", line_encode_fn=encode),\n",
    "    target_key=[\"targets\", \"targets_length\"],\n",
    "    batch_size=1, shuffle=False, num_epochs=1,\n",
    "    queue_capacity=1024, num_threads=1,\n",
    "    pad_value=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "log_dir = \"./logs_170620_tatoeba_en_ru\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gpu_options = tf.GPUOptions(per_process_gpu_memory_fraction=0.5)\n",
    "run_config = tf.contrib.learn.RunConfig(\n",
    "    session_config=tf.ConfigProto(gpu_options=gpu_options),\n",
    "    model_dir=log_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open(\"{}/hparams.json\".format(log_dir)) as fout:\n",
    "    values = json.load(fout)\n",
    "#     values = fout.readline()\n",
    "# @TODO: for some reason tf.parse_values does not work :(\n",
    "hparams = tf.contrib.training.HParams()\n",
    "for key, value in values.items():\n",
    "    hparams.add_hparam(key, value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using config: {'_save_checkpoints_steps': None, '_num_worker_replicas': 0, '_master': '', '_evaluation_master': '', '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f246b5ca9e8>, '_tf_random_seed': None, '_num_ps_replicas': 0, '_is_chief': True, '_keep_checkpoint_max': 5, '_task_type': None, '_environment': 'local', '_session_config': gpu_options {\n",
      "  per_process_gpu_memory_fraction: 0.5\n",
      "}\n",
      ", '_tf_config': gpu_options {\n",
      "  per_process_gpu_memory_fraction: 1.0\n",
      "}\n",
      ", '_task_id': 0, '_model_dir': './logs_170620_tatoeba_en_ru', '_keep_checkpoint_every_n_hours': 10000, '_save_summary_steps': 100, '_save_checkpoints_secs': 600}\n"
     ]
    }
   ],
   "source": [
    "model = create_seq2seq_model(config=run_config, hparams=hparams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predictions = model.predict(val_input_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./logs_170620_tatoeba_en_ru/model.ckpt-758201\n",
      "том сказал что больше не сделает этого\n",
      "--------------------------------------------------------------------------------\n",
      "tom said that he would do not to do that\n",
      "--------------------------------------------------------------------------------\n",
      "у тома хороший сердце\n",
      "--------------------------------------------------------------------------------\n",
      "tom has a heart heart\n",
      "--------------------------------------------------------------------------------\n",
      "мне нужно по@@ си@@ ё@@ ваться\n",
      "--------------------------------------------------------------------------------\n",
      "i have no stop anywhere\n",
      "--------------------------------------------------------------------------------\n",
      "объяс@@ ните правила мне в этой футбо@@\n",
      "--------------------------------------------------------------------------------\n",
      "please explain me the rules of the football\n",
      "--------------------------------------------------------------------------------\n",
      "он уехал\n",
      "--------------------------------------------------------------------------------\n",
      "he left\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for i, pred in enumerate(predictions):\n",
    "    if i >= 10:\n",
    "        break\n",
    "    print(decode(pred[\"prediction\"].reshape(-1)))\n",
    "    print(\"-\"*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'attention': 'bahdanau',\n",
       " 'beam_width': 3,\n",
       " 'bidirectional': False,\n",
       " 'cell': 'LSTMCell',\n",
       " 'cell_num': 1,\n",
       " 'embedding_size': 128,\n",
       " 'gradient_clip': 10.0,\n",
       " 'inference_mode': 'greedy',\n",
       " 'learning_rate': 0.0001,\n",
       " 'lr_decay_koef': 0.99,\n",
       " 'lr_decay_steps': 100000,\n",
       " 'num_layers': 2,\n",
       " 'num_units': 128,\n",
       " 'residual_connections': True,\n",
       " 'residual_dense': True,\n",
       " 'scheduled_sampling_probability': 0.2,\n",
       " 'training_mode': 'scheduled_sampling_embedding',\n",
       " 'vocab_size': 9775}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hparams.values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "hparams.inference_mode =  \"beam\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'attention': 'bahdanau',\n",
       " 'beam_width': 3,\n",
       " 'bidirectional': False,\n",
       " 'cell': 'LSTMCell',\n",
       " 'cell_num': 1,\n",
       " 'embedding_size': 128,\n",
       " 'gradient_clip': 10.0,\n",
       " 'inference_mode': 'beam',\n",
       " 'learning_rate': 0.0001,\n",
       " 'lr_decay_koef': 0.99,\n",
       " 'lr_decay_steps': 100000,\n",
       " 'num_layers': 2,\n",
       " 'num_units': 128,\n",
       " 'residual_connections': True,\n",
       " 'residual_dense': True,\n",
       " 'scheduled_sampling_probability': 0.2,\n",
       " 'training_mode': 'scheduled_sampling_embedding',\n",
       " 'vocab_size': 9775}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hparams.values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "val_input_fn = generator_input_fn(\n",
    "    x=file_data_generator_py(\"./data/tatoeba_en_ru/test.txt\", line_encode_fn=encode),\n",
    "    target_key=[\"targets\", \"targets_length\"],\n",
    "    batch_size=1, shuffle=False, num_epochs=1,\n",
    "    queue_capacity=1024, num_threads=1,\n",
    "    pad_data=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using config: {'_save_checkpoints_steps': None, '_num_worker_replicas': 0, '_master': '', '_evaluation_master': '', '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f246b5ca9e8>, '_tf_random_seed': None, '_num_ps_replicas': 0, '_is_chief': True, '_keep_checkpoint_max': 5, '_task_type': None, '_environment': 'local', '_session_config': gpu_options {\n",
      "  per_process_gpu_memory_fraction: 0.5\n",
      "}\n",
      ", '_tf_config': gpu_options {\n",
      "  per_process_gpu_memory_fraction: 1.0\n",
      "}\n",
      ", '_task_id': 0, '_model_dir': './logs_170620_tatoeba_en_ru', '_keep_checkpoint_every_n_hours': 10000, '_save_summary_steps': 100, '_save_checkpoints_secs': 600}\n"
     ]
    }
   ],
   "source": [
    "model = create_seq2seq_model(config=run_config, hparams=hparams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predictions = model.predict(val_input_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./logs_170620_tatoeba_en_ru/model.ckpt-758201\n",
      "том сказал что больше этого больше не сделает\n",
      "том сказал что больше не сделает этого больше\n",
      "том сказал что больше этого не сделает этого\n",
      "--------------------------------------------------------------------------------\n",
      "did said he would be done that\n",
      "did said he would be done that\n",
      "did said he would do not do that\n",
      "--------------------------------------------------------------------------------\n",
      "у тома добро@@ е сердце\n",
      "у тома добро@@ е сердце\n",
      "у него добро@@ серде@@ чный хороший\n",
      "--------------------------------------------------------------------------------\n",
      "tom have a heart heart\n",
      "tom has a heart heart\n",
      "tom have a heart\n",
      "--------------------------------------------------------------------------------\n",
      "мне не нужно остаться\n",
      "мне мне остаться\n",
      "мне мне остаться остаться\n",
      "--------------------------------------------------------------------------------\n",
      "should no longer to stop\n",
      "should no longer to stop anywhere\n",
      "should no longer stop\n",
      "--------------------------------------------------------------------------------\n",
      "пожалуйста объяс@@ ни правила мне фут@@\n",
      "пожалуйста объяс@@ ните правила мне фут@@\n",
      "пожалуйста объяс@@ ни правила эту футбо@@\n",
      "--------------------------------------------------------------------------------\n",
      "please explain me the rules of the football\n",
      "please explain me the rules of the soccer\n",
      "please explain me the rules to the soccer\n",
      "--------------------------------------------------------------------------------\n",
      "empty ушёл уехал\n",
      "empty ушёл отправился\n",
      "empty ушёл пошёл\n",
      "--------------------------------------------------------------------------------\n",
      "quit left\n",
      "quit gone away\n",
      "quit gone gone away\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for i, pred in enumerate(predictions):\n",
    "    if i >= 10:\n",
    "        break\n",
    "    for beam_pred in pred[\"prediction\"].swapaxes(0, 1):\n",
    "        print(decode(beam_pred))\n",
    "    print(\"-\"*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
